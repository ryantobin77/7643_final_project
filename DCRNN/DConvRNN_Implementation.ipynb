{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCBR9XTfb23O"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db1P1bSYqPyk"
      },
      "outputs": [],
      "source": [
        "!pip install torch-geometric-temporal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGpDjbYHsg-J",
        "outputId": "395adea1-30d6-480a-93af-b8fb7c8be78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.utils import to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
        "from torch_geometric_temporal.dataset import PemsBayDatasetLoader\n",
        "from torch_geometric_temporal.signal import temporal_signal_split\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psKcrzEzbwBe"
      },
      "source": [
        "### DConvRNN Model Implementation\n",
        "##### Paper: https://arxiv.org/abs/1707.01926"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XybgLu9wGWvh"
      },
      "outputs": [],
      "source": [
        "class DCRLayer(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, C):\n",
        "      super(DCRLayer, self).__init__(aggr='add', flow='source_to_target')\n",
        "      self.in_channels = in_channels\n",
        "      self.out_channels = out_channels\n",
        "      self.C = C\n",
        "      self.weight = torch.nn.Parameter(torch.Tensor(2, self.C, self.in_channels, self.out_channels)).to(device)\n",
        "      torch.nn.init.xavier_uniform_(self.weight)\n",
        "      self.bias = torch.nn.Parameter(torch.zeros(out_channels)).to(device)\n",
        "\n",
        "    def message(self, x_i, norm):\n",
        "      val = x_i * norm.view(-1, 1)\n",
        "      return val\n",
        "\n",
        "    def forward(self, input, edge_index, edge_weight):\n",
        "        i, j = edge_index\n",
        "        matrix = to_dense_adj(edge_index=edge_index, edge_attr=edge_weight).to(device)\n",
        "        matrix = torch.reshape(input=matrix, shape=(matrix.shape[1], matrix.shape[2])).to(device)\n",
        "        ones = torch.ones((matrix.shape[0], 1)).to(device)\n",
        "        out_degree = torch.matmul(matrix, ones).flatten().to(device)\n",
        "        out_degree_inverse = torch.reciprocal(out_degree)\n",
        "        out_norm = out_degree_inverse[i]\n",
        "\n",
        "        in_degree = torch.matmul(ones.T, matrix).flatten()\n",
        "        in_degree_inverse = torch.reciprocal(in_degree)\n",
        "        in_norm = in_degree_inverse[i]\n",
        "\n",
        "        edge_index_reverse, _ = dense_to_sparse(matrix.T)\n",
        "\n",
        "        result = torch.matmul(input, (self.weight[0])[0]) + torch.matmul(input, (self.weight[1])[0])\n",
        "        if self.weight.shape[1] > 1:\n",
        "          p_0 = self.propagate(edge_index, x=input, norm=out_norm, size=None)\n",
        "          p_1 = self.propagate(edge_index_reverse, x=input, norm=in_norm, size=None)\n",
        "          result = result + torch.matmul(p_0, (self.weight[0])[1]) + torch.matmul(p_1, (self.weight[1])[1])\n",
        "\n",
        "        X_0 = input\n",
        "        X_1 = input\n",
        "        for x in range(2, self.weight.shape[1]):\n",
        "            p_x_0 = self.propagate(edge_index, x=p_0, norm=out_norm, size=None)\n",
        "            p_x_0 = 2.0 * p_x_0 - X_0\n",
        "            p_x_1 = self.propagate(edge_index_reverse, x=p_1, norm=in_norm, size=None)\n",
        "            p_x_1 = 2.0 * p_x_1 - X_0\n",
        "            result = result + torch.matmul(p_x_0, (self.weight[0])[x]) + torch.matmul(p_x_1, (self.weight[1])[x])\n",
        "            X_0 = X_1\n",
        "            p_0 = p_x_0\n",
        "            p_1 = p_x_1\n",
        "\n",
        "        result += self.bias\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nDBNnFJkpBIi"
      },
      "outputs": [],
      "source": [
        "class DCGRU(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, C):\n",
        "    super(DCGRU, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.C = C\n",
        "\n",
        "    # Update\n",
        "    self.conv_layer_1 = DCRLayer(in_channels=self.in_channels + self.out_channels, out_channels=self.out_channels, C=self.C).to(device)\n",
        "    self.sigmoid_1 = nn.Sigmoid()\n",
        "    # Reset\n",
        "    self.conv_layer_2 = DCRLayer(in_channels=self.in_channels + self.out_channels, out_channels=self.out_channels, C=self.C).to(device)\n",
        "    self.sigmoid_2 = nn.Sigmoid()\n",
        "    # Candidate\n",
        "    self.conv_layer_3 = DCRLayer(in_channels=self.in_channels + self.out_channels, out_channels=self.out_channels, C=self.C).to(device)\n",
        "    self.sigmoid_3 = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input, edge_weight, edge_index, hidden=None):\n",
        "    # Update\n",
        "    outs_1 = torch.cat([input, hidden], dim=-1).to(device)\n",
        "    outs_1 = self.conv_layer_1(outs_1, edge_index, edge_weight).to(device)\n",
        "    outs_1 = self.sigmoid_1(outs_1).to(device)\n",
        "\n",
        "    # Reset\n",
        "    outs_2 = torch.cat([input, hidden], dim=-1).to(device)\n",
        "    outs_2 = self.conv_layer_2(outs_2, edge_index, edge_weight).to(device)\n",
        "    outs_2 = self.sigmoid_2(outs_2).to(device)\n",
        "\n",
        "    # Candidate\n",
        "    hidden_3 = hidden * outs_2\n",
        "    outs_3 = torch.cat([input, hidden_3], dim=-1).to(device)\n",
        "    outs_3 = self.conv_layer_3(outs_3, edge_index, edge_weight).to(device)\n",
        "    outs_3 = self.sigmoid_3(outs_3).to(device)\n",
        "\n",
        "    result = outs_1 * hidden + (1 - outs_1) * outs_3\n",
        "    return result.to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oKyVpX-KNBUC"
      },
      "outputs": [],
      "source": [
        "class DCEncoder(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, C):\n",
        "    super(DCEncoder, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.C = C\n",
        "    self.layer_1 = DCGRU(in_channels=self.in_channels, out_channels=self.out_channels, C=self.C).to(device)\n",
        "    self.layer_2 = DCGRU(in_channels=self.out_channels, out_channels=self.out_channels, C=self.C).to(device)\n",
        "\n",
        "  def forward(self, input, edge_weight, edge_index, hidden_states):\n",
        "    hiddens = []\n",
        "    outs = self.layer_1(input, edge_weight, edge_index, hidden=hidden_states[0]).to(device)\n",
        "    hiddens.append(outs)\n",
        "    outs = self.layer_2(outs, edge_weight, edge_index, hidden=hidden_states[1]).to(device)\n",
        "    hiddens.append(outs)\n",
        "    return outs, hiddens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m8oVRSPcPMMI"
      },
      "outputs": [],
      "source": [
        "class DCDecoder(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, output_dim, C):\n",
        "    super(DCDecoder, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.C = C\n",
        "    self.layer_1 = DCGRU(in_channels=self.in_channels, out_channels=self.out_channels, C=self.C).to(device)\n",
        "    self.layer_2 = DCGRU(in_channels=self.out_channels, out_channels=self.out_channels, C=self.C).to(device)\n",
        "    self.fc_layer = nn.Linear(self.out_channels, self.output_dim).to(device)\n",
        "\n",
        "  def forward(self, input, edge_weight, edge_index, hidden_states):\n",
        "    hiddens = []\n",
        "    outs = self.layer_1(input.to(device), edge_weight.to(device), edge_index.to(device), hidden=hidden_states[0].to(device)).to(device)\n",
        "    hiddens.append(outs)\n",
        "    outs = self.layer_2(outs.to(device), edge_weight.to(device), edge_index.to(device), hidden=hidden_states[1].to(device)).to(device)\n",
        "    hiddens.append(outs)\n",
        "    outs = self.fc_layer(outs.to(device)).to(device)\n",
        "    return outs.to(device), hiddens\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8gIADse-tuXS"
      },
      "outputs": [],
      "source": [
        "class DConvRNN(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, output_dim, C):\n",
        "    super(DConvRNN, self).__init__()\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "    self.output_dim = output_dim\n",
        "    self.C = C\n",
        "    self.encoder = DCEncoder(self.in_channels, self.out_channels, self.C)\n",
        "    self.decoder = DCDecoder(self.in_channels, self.out_channels, self.output_dim, self.C)\n",
        "\n",
        "  def encode(self, input, edge_weight, edge_index):\n",
        "    hidden_states = [\n",
        "      torch.zeros(input.shape[0], self.out_channels).to(device),\n",
        "      torch.zeros(input.shape[0], self.out_channels).to(device)\n",
        "    ]\n",
        "    _, hidden_states = self.encoder(input, edge_weight, edge_index, hidden_states)\n",
        "    return hidden_states\n",
        "\n",
        "  def decode(self, input, edge_weight, edge_index, hidden_states):\n",
        "    outputs, hidden_states = self.decoder(input.to(device), edge_weight.to(device), edge_index.to(device), hidden_states)\n",
        "    return outputs\n",
        "\n",
        "  def forward(self, input, predictions, edge_weight, edge_index):\n",
        "    hidden = self.encode(input, edge_weight, edge_index)\n",
        "    outputs = self.decode(predictions.to(device), edge_weight.to(device), edge_index.to(device), hidden)\n",
        "    return outputs\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DConvRNN(\n",
            "  (encoder): DCEncoder(\n",
            "    (layer_1): DCGRU(\n",
            "      (conv_layer_1): DCRLayer(44, 32)\n",
            "      (sigmoid_1): Sigmoid()\n",
            "      (conv_layer_2): DCRLayer(44, 32)\n",
            "      (sigmoid_2): Sigmoid()\n",
            "      (conv_layer_3): DCRLayer(44, 32)\n",
            "      (sigmoid_3): Sigmoid()\n",
            "    )\n",
            "    (layer_2): DCGRU(\n",
            "      (conv_layer_1): DCRLayer(64, 32)\n",
            "      (sigmoid_1): Sigmoid()\n",
            "      (conv_layer_2): DCRLayer(64, 32)\n",
            "      (sigmoid_2): Sigmoid()\n",
            "      (conv_layer_3): DCRLayer(64, 32)\n",
            "      (sigmoid_3): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (decoder): DCDecoder(\n",
            "    (layer_1): DCGRU(\n",
            "      (conv_layer_1): DCRLayer(44, 32)\n",
            "      (sigmoid_1): Sigmoid()\n",
            "      (conv_layer_2): DCRLayer(44, 32)\n",
            "      (sigmoid_2): Sigmoid()\n",
            "      (conv_layer_3): DCRLayer(44, 32)\n",
            "      (sigmoid_3): Sigmoid()\n",
            "    )\n",
            "    (layer_2): DCGRU(\n",
            "      (conv_layer_1): DCRLayer(64, 32)\n",
            "      (sigmoid_1): Sigmoid()\n",
            "      (conv_layer_2): DCRLayer(64, 32)\n",
            "      (sigmoid_2): Sigmoid()\n",
            "      (conv_layer_3): DCRLayer(64, 32)\n",
            "      (sigmoid_3): Sigmoid()\n",
            "    )\n",
            "    (fc_layer): Linear(in_features=32, out_features=12, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "dcrnn = DConvRNN(in_channels=12, out_channels=32, output_dim=12, C=2)\n",
        "print(dcrnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qx3iznB0s7p"
      },
      "source": [
        "### Build Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz1FFqxD2QCm"
      },
      "source": [
        "Metr LA Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5BT5qEs-0vz-"
      },
      "outputs": [],
      "source": [
        "metr_la_loader = METRLADatasetLoader()\n",
        "metr_la_dataset = metr_la_loader.get_dataset()\n",
        "metr_la_train_dataset, metr_la_val_dataset = temporal_signal_split(metr_la_dataset, train_ratio=0.7)\n",
        "metr_la_val_dataset, metr_la_test_dataset = temporal_signal_split(metr_la_val_dataset, train_ratio=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXW4BgL8SaCM"
      },
      "source": [
        "Pems Bay Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_jX6-9jUSWOl"
      },
      "outputs": [],
      "source": [
        "pems_bay_loader = PemsBayDatasetLoader()\n",
        "pems_bay_dataset = pems_bay_loader.get_dataset()\n",
        "pems_bay_train_dataset, pems_bay_val_dataset = temporal_signal_split(pems_bay_dataset, train_ratio=0.7)\n",
        "pems_bay_val_dataset, pems_bay_test_dataset = temporal_signal_split(pems_bay_val_dataset, train_ratio=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5cfWiHs0ZbI"
      },
      "source": [
        "### Train and Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7IxJ6m-A0cmA"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, loss_fn, num_epochs, train_dataset_loader, val_dataset_loader, is_la=True):\n",
        "  model.train()\n",
        "  for epoch in range(num_epochs):\n",
        "    print(\"Epoch: \" + str(epoch + 1) + \" / \" + str(num_epochs))\n",
        "    total_loss = 0\n",
        "    total_len = 0\n",
        "    rmse = 0\n",
        "    mae = 0\n",
        "    mape = 0\n",
        "    for _, snapshot in tqdm(enumerate(train_dataset_loader)):\n",
        "      optimizer.zero_grad()\n",
        "      input = snapshot.x[:, 0, :]\n",
        "      target = snapshot.y.to(device) if is_la else snapshot.y[:, 0, :].to(device)\n",
        "      edge_weight = snapshot.edge_attr.to(device)\n",
        "      edge_index = snapshot.edge_index.to(device)\n",
        "      predictions = model(input.to(device), target.to(device), edge_weight.to(device), edge_index.to(device)).to(device)\n",
        "      \n",
        "      loss = loss_fn(predictions, target)\n",
        "      loss.backward()\n",
        "      total_loss += loss.item()\n",
        "      optimizer.step()\n",
        "\n",
        "      rmse += mean_squared_error(target.detach().cpu().numpy(), predictions.detach().cpu().numpy(), squared=False)\n",
        "      mae += mean_absolute_error(target.detach().cpu().numpy(), predictions.detach().cpu().numpy())\n",
        "      mape += mean_absolute_percentage_error(target.detach().cpu().numpy(), predictions.detach().cpu().numpy())\n",
        "      total_len += 1\n",
        "    \n",
        "    epoch_loss = total_loss / total_len\n",
        "    rmse /= total_len\n",
        "    mae /= total_len\n",
        "    mape /= total_len\n",
        "    print(\"Epoch {} train Loss: {:.4f}, train RMSE: {:.4f}, train MAE: {:.4f}, train MAPE: {:.4f}\".format(epoch, epoch_loss, rmse, mae, mape))\n",
        "    val_loss, val_rmse, val_mae, val_mape = eval_model(model, loss_fn, val_dataset_loader, is_la)\n",
        "    print(\"Epoch {} val Loss: {:.4f}, val RMSE: {:.4f}, val MAE: {:.4f}, val MAPE: {:.4f}\".format(epoch, val_loss, val_rmse, val_mae, val_mape))\n",
        "  \n",
        "\n",
        "def eval_model(model, loss_fn, val_dataset_loader, is_la=True):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  total_len = 0\n",
        "  rmse = 0\n",
        "  mae = 0\n",
        "  mape = 0\n",
        "  with torch.no_grad():\n",
        "    for _, snapshot in tqdm(enumerate(val_dataset_loader)):\n",
        "      input = snapshot.x[:, 0, :]\n",
        "      target = snapshot.y.to(device) if is_la else snapshot.y[:, 0, :].to(device)\n",
        "      edge_weight = snapshot.edge_attr.to(device)\n",
        "      edge_index = snapshot.edge_index.to(device)\n",
        "      if total_len == 0:\n",
        "        predictions = torch.randn_like(target).to(device)\n",
        "      predictions = model(input.to(device), predictions.to(device), edge_weight.to(device), edge_index.to(device)).to(device)\n",
        "      loss = loss_fn(predictions, target)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      rmse += mean_squared_error(target.detach().cpu().numpy(), predictions.detach().cpu().numpy(), squared=False)\n",
        "      mae += mean_absolute_error(target.detach().cpu().numpy(), predictions.detach().cpu().numpy())\n",
        "      mape += mean_absolute_percentage_error(target.detach().cpu().numpy(), predictions.detach().cpu().numpy())\n",
        "      total_len += 1\n",
        "    \n",
        "    val_loss = total_loss / total_len\n",
        "    rmse /= total_len\n",
        "    mae /= total_len\n",
        "    mape /= total_len\n",
        "  return val_loss, rmse, mae, mape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilkmY4cgSS8b"
      },
      "source": [
        "### Train and Test LA Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpnRsE-9G_LJ",
        "outputId": "adb10d3e-4c68-4605-89f6-12b306dc47f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23974it [14:24, 27.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 train Loss: 0.0246, train RMSE: 0.1022, train MAE: 0.0683, train MAPE: 0.4132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5137it [01:48, 47.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 val Loss: 3.9307, val RMSE: 1.9685, val MAE: 1.5856, val MAPE: 7.4804\n",
            "Epoch: 2 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23974it [14:40, 27.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 train Loss: 0.0055, train RMSE: 0.0462, train MAE: 0.0308, train MAPE: 0.1563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5137it [01:52, 45.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 val Loss: 4.4387, val RMSE: 2.0864, val MAE: 1.6972, val MAPE: 8.4164\n",
            "Epoch: 3 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23974it [15:17, 26.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 train Loss: 0.0041, train RMSE: 0.0377, train MAE: 0.0256, train MAPE: 0.1299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5137it [01:34, 54.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 val Loss: 4.9163, val RMSE: 2.1914, val MAE: 1.8034, val MAPE: 8.9767\n",
            "Epoch: 4 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23974it [14:22, 27.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 train Loss: 0.0031, train RMSE: 0.0317, train MAE: 0.0216, train MAPE: 0.1123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5137it [01:41, 50.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 val Loss: 4.9988, val RMSE: 2.2146, val MAE: 1.8099, val MAPE: 9.1985\n",
            "Epoch: 5 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "23974it [15:20, 26.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 train Loss: 0.0024, train RMSE: 0.0275, train MAE: 0.0188, train MAPE: 0.0996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5137it [01:48, 47.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 val Loss: 4.6748, val RMSE: 2.1446, val MAE: 1.7085, val MAPE: 8.0834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "la_model = DConvRNN(in_channels=12, out_channels=32, output_dim=12, C=2)\n",
        "optimizer = torch.optim.Adam(la_model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "train_model(la_model, optimizer, loss_fn, 5, metr_la_train_dataset, metr_la_val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY_8J4p5O1pU",
        "outputId": "cf1bba4a-7f12-441e-c98f-39fc1879ade5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5138it [01:34, 54.64it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.6412, test RMSE: 2.1410, test MAE: 1.6952, test MAPE: 8.0144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_rmse, test_mae, test_mape = eval_model(la_model, loss_fn, metr_la_test_dataset)\n",
        "print(\"Test Loss: {:.4f}, test RMSE: {:.4f}, test MAE: {:.4f}, test MAPE: {:.4f}\".format(test_loss, test_rmse, test_mae, test_mape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW9YkjEyS0UV"
      },
      "source": [
        "### Train and Test Pems Bay Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqeD8240S3Jm",
        "outputId": "b4c2fe3b-debd-43bc-9c77-c7c015bf09d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36457it [34:26, 17.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 train Loss: 0.0073, train RMSE: 0.0611, train MAE: 0.0373, train MAPE: 0.2154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7812it [04:06, 31.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 val Loss: 3.4305, val RMSE: 1.7984, val MAE: 1.4061, val MAPE: 8.2047\n",
            "Epoch: 2 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36457it [38:52, 15.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 train Loss: 0.0008, train RMSE: 0.0187, train MAE: 0.0108, train MAPE: 0.0568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7812it [03:42, 35.17it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 val Loss: 6.5686, val RMSE: 2.5020, val MAE: 2.0015, val MAPE: 11.6901\n",
            "Epoch: 3 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36457it [33:50, 17.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 train Loss: 0.0006, train RMSE: 0.0152, train MAE: 0.0091, train MAPE: 0.0475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7812it [04:15, 30.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 val Loss: 8.9896, val RMSE: 2.9385, val MAE: 2.4566, val MAPE: 14.6030\n",
            "Epoch: 4 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36457it [30:05, 20.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 train Loss: 0.0005, train RMSE: 0.0135, train MAE: 0.0082, train MAPE: 0.0425\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7812it [03:34, 36.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 val Loss: 6.8991, val RMSE: 2.5876, val MAE: 1.9976, val MAPE: 12.2093\n",
            "Epoch: 5 / 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "36457it [31:14, 19.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 train Loss: 0.0004, train RMSE: 0.0124, train MAE: 0.0076, train MAPE: 0.0392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7812it [03:47, 34.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 val Loss: 7.8628, val RMSE: 2.7498, val MAE: 2.1430, val MAPE: 12.3037\n"
          ]
        }
      ],
      "source": [
        "pems_model = DConvRNN(in_channels=12, out_channels=32, output_dim=12, C=2)\n",
        "optimizer = torch.optim.Adam(pems_model.parameters(), lr=0.001)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "train_model(pems_model, optimizer, loss_fn, 5, pems_bay_train_dataset, pems_bay_val_dataset, is_la=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kUQkS-GS3zN",
        "outputId": "3f6d579a-418f-411b-faf3-494b54e67370"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "7813it [03:23, 38.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 7.5590, test RMSE: 2.7034, test MAE: 2.1133, test MAPE: 13.3226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_rmse, test_mae, test_mape = eval_model(pems_model, loss_fn, pems_bay_test_dataset, is_la=False)\n",
        "print(\"Test Loss: {:.4f}, test RMSE: {:.4f}, test MAE: {:.4f}, test MAPE: {:.4f}\".format(test_loss, test_rmse, test_mae, test_mape))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
